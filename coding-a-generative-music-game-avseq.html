<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Coding a generative music game – AvSeq - NULLPOINTER</title><meta name="description" content="This post outlines some of the technical issues and solutions connected with&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://tomnullpointer.github.io/gh-pages/coding-a-generative-music-game-avseq.html"><link rel="alternate" type="application/atom+xml" href="https://tomnullpointer.github.io/gh-pages/feed.xml" title="NULLPOINTER - RSS"><link rel="alternate" type="application/json" href="https://tomnullpointer.github.io/gh-pages/feed.json" title="NULLPOINTER - JSON"><meta property="og:title" content="Coding a generative music game – AvSeq"><meta property="og:image" content="https://tomnullpointer.github.io/gh-pages/media/posts/13/ss_907cc5a3b4478e531440c45cb9d84e1485734d43.1920x1080.jpg"><meta property="og:image:width" content="1920"><meta property="og:image:height" content="1080"><meta property="og:site_name" content="NULLPOINTER"><meta property="og:description" content="This post outlines some of the technical issues and solutions connected with&hellip;"><meta property="og:url" content="https://tomnullpointer.github.io/gh-pages/coding-a-generative-music-game-avseq.html"><meta property="og:type" content="article"><link rel="preload" href="https://tomnullpointer.github.io/gh-pages/assets/dynamic/fonts/publicsans/publicsans.woff2" as="font" type="font/woff2" crossorigin><link rel="stylesheet" href="https://tomnullpointer.github.io/gh-pages/assets/css/style.css?v=e4d9dbb286ed39acbd89c04735d2c531"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://tomnullpointer.github.io/gh-pages/coding-a-generative-music-game-avseq.html"},"headline":"Coding a generative music game – AvSeq","datePublished":"2025-10-04T19:18+01:00","dateModified":"2025-10-05T10:14+01:00","image":{"@type":"ImageObject","url":"https://tomnullpointer.github.io/gh-pages/media/posts/13/ss_907cc5a3b4478e531440c45cb9d84e1485734d43.1920x1080.jpg","height":1080,"width":1920},"description":"This post outlines some of the technical issues and solutions connected with&hellip;","author":{"@type":"Person","name":"me","url":"https://tomnullpointer.github.io/gh-pages/authors/me/"},"publisher":{"@type":"Organization","name":"me"}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="post-template"><div class="container"><div class="left-bar"><div class="left-bar__inner"><header class="header"><a class="logo" href="https://tomnullpointer.github.io/gh-pages/">NULLPOINTER</a><nav class="navbar"><button class="navbar__toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle__box"><span class="navbar__toggle__inner">Menu</span></span></button><ul class="navbar__menu"></ul></nav><a class="logo logo--atbottom" href="https://tomnullpointer.github.io/gh-pages/">NULLPOINTER</a></header></div></div><main class="main post"><article class="content"><figure class="content__featured-image content__featured-image--attop"><img src="https://tomnullpointer.github.io/gh-pages/media/posts/13/ss_907cc5a3b4478e531440c45cb9d84e1485734d43.1920x1080.jpg" srcset="https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ss_907cc5a3b4478e531440c45cb9d84e1485734d43.1920x1080-xs.jpg 320w, https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ss_907cc5a3b4478e531440c45cb9d84e1485734d43.1920x1080-sm.jpg 480w, https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ss_907cc5a3b4478e531440c45cb9d84e1485734d43.1920x1080-md.jpg 768w, https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ss_907cc5a3b4478e531440c45cb9d84e1485734d43.1920x1080-xl.jpg 1024w" sizes="(min-width: 1460px) 938px, (min-width: 1200px) calc(75.83vw - 154px), (min-width: 1120px) 938px, (min-width: 900px) calc(55vw + 333px), 100vw" loading="eager" height="1080" width="1920" alt="" aria-describedby="image-caption"></figure><div class="main__inner"><div class="content__meta"><div class="content__date"><time datetime="2025-10-04T19:18">Oct 4, 2025</time></div></div><header class="content__header"><h1 class="content__title">Coding a generative music game – AvSeq</h1></header><div class="content__entry"><figure class="post__image"><img loading="lazy" src="https://tomnullpointer.github.io/gh-pages/media/posts/13/ResHubAvseq1.jpg" alt="" width="910" height="400" sizes="(min-width: 760px) 660px, calc(93.18vw - 30px)" srcset="https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq1-xs.jpg 320w, https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq1-sm.jpg 480w, https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq1-md.jpg 768w, https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq1-xl.jpg 1024w"></figure><p><br><br></p><div class="entry-content"><article><p>This post outlines some of the technical issues and solutions connected with the development of AvSeq, the first game produced for my PhD research. More generalised information about the game is available <a href="http://www.nullpointer.co.uk/content/avseq-3/">here</a></p><h2>Accurate high frequency audio timing and quantization in Unity</h2><p>During the development of AvSeq I needed to find a way to get a high accuracy audiotimer to trigger audiovisual events in perfect synchronization. Unity is primarily a games engine and had not built-in functionality to support this type of requirement. In libraries like portaudio the code provides a callback function that can deliver buffered content to the soundcard, down to the level of a single sample. In Unity the update threads run at a much slower rate and cant be used for reliable timing. Unity also discourages the use of threads and out-of-update callbacks so I had to find another way. The solution I came up with was to leverage the built in functions of the packaged FMOD library. I particular this library provides functions to<br>grab the current playpoint of a sample and also trigger a sample with a specific pre-roll delay.<br>I used these features in the following steps.</p><ol><li>Setup and play a hardware looping metronome via FMOD. This can be a standard clicktrack sample or even a silent audiofile. The length and playback pitch of the file represents a single audio-beat cycle that can be tracked in code.</li><li>Run a FixedUpdate (or any fast thread) and within this request the the current PCM sample position of the metronome.</li><li>Use this position to detect if the current loop of the metronome sample is nearing its end. The margin of error for this ‘catching’ process detect depends on the frequency of your update and the pitch/frequency of the metronome.</li><li>If the retrieved PCM location is close enough to the next loop point then trigger a new sound to play BUT set the new sample pre-roll to the remaining samples in the current loop (loop sample length- current sample position).</li><li>Don’t create or run any further triggers until the retrieved position has looped back over the zero-point.<em><br></em></li></ol><p>This system allows accuracy up until a relatively high tempo rate (dependent on individual machine speed), and allows the sample accurate triggering and quantizing of triggered audiosources. The tempo of the entire system can be adjusted by varying the playback pitch of the reference metronome, for example a metronome sample of 1 second length, will define a bpm of 60. At double the metronome pitch the bpm will be 120. The ‘catch’ margin can be adjusted dynamically as a percentage of this overall length if you want real-time pitch changes like I use in AvSeq. In AvSeq I also use the looping reference sample to keep track of beats/bars in the total sequence and each new beat trigger the playback of samples assigned to that beat in the sequencer score.</p><p>Some example code:</p><pre>	void FixedUpdate () {

		m_MS=m_ASMetronome.timeSamples;//get the current position of the looping reference sample
		uint catchup=0;
		float delay=0;

		if(m_MS&lt;m_CatchMargin &amp;&amp; m_HasLooped==1)//check to see if the reference sample has looped and has been dealt with
		{
			m_HasLooped=0;//reset the haslooped indicator
		}

		//catch end of loop
		if(m_MS&gt;m_SampleLength-m_CatchMargin)
		{
			m_MSCatch=m_MS;

			//only do if we havent marked a new loop yet
			if(m_HasLooped==0)
			{
			catchup=(uint)(m_SampleLength-m_MS);	//work out how long to delay the start of any new sample
			m_HasLooped=1;	//register that we have dealt with the current loop
			m_AudioSource.Play(catchup);//play a sample with the correct delay to coincide with the actual loop point
			}
		}
              }
</pre><p>There’s a bit more discussion and some extensions of the technique discussed at <a href="http://forum.unity3d.com/threads/audio-stepsequencer-and-they-said-it-couldnt-be-done.78003/">http://forum.unity3d.com/threads/audio-stepsequencer-and-they-said-it-couldnt-be-done.78003/</a> </p><h2>Video Feedback effect in Unity</h2><p>I wanted AvSeq to feature some form of video feedback, discovered in camera/tv loop experiments of the 1980s. You can see the effect in this video <a href="https://www.youtube.com/watch?v=eD9rr0gTLSU">https://www.youtube.com/watch?v=eD9rr0gTLSU</a> (although its a recent video, the actual technique is the same). To achieve this I mimicked the feedback loop by rendering a subset of the games geometry to an offscreen surface and then drawing that image in the background of the scene. This meant that each frame of gameplay also had a degree of the previous frame set behind the current objects. By altering the transparency of the previous frame image the system can control the amount of feedback and blur that occurs. The scene setup for this process is show below.</p><figure class="post__image"><img loading="lazy" src="https://tomnullpointer.github.io/gh-pages/media/posts/13/ResHubAvseq2.jpg" alt="" width="1448" height="680" sizes="(min-width: 760px) 660px, calc(93.18vw - 30px)" srcset="https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq2-xs.jpg 320w, https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq2-sm.jpg 480w, https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq2-md.jpg 768w, https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq2-xl.jpg 1024w"></figure><ul><li>A: Shows the scene from a point close to the player perspective, but with the camera pulled back slightly to show the edges of the background screen. The image shows the foreground cubes and their after-images on the background screen (one cube is even passing through the background screen)</li><li><br>B: Shows the positioning of the background screen and the ‘invisible’ offscreen rendering camera. The cubes can easily be seen in front of the screen, within the normal playspace of the game.</li><li><br>C: shows the image viewed from the offscreen rendering camera. This image is then drawn onto the background screen during the next frame.</li></ul><p>Some compensation has to be made to account for offscreen texture surfaces being square and the scene view being landscape, but these are trivial ratio adjustments. In AvSeq I used additive blending on the background screen, in order to control the persistence of each frame and its feedback, but other blending methods can be used to generate more radical effects. Similarly the polygon mesh of the background plane can be warped to force the feedback to flow in a specific direction. Although I avoided extreme warping in the final game version, some of the prototypes demonstrate the effect more clearly.</p><figure class="post__image"><img loading="lazy" src="https://tomnullpointer.github.io/gh-pages/media/posts/13/ResHubAvseq3.jpg" alt="" width="912" height="412" sizes="(min-width: 760px) 660px, calc(93.18vw - 30px)" srcset="https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq3-xs.jpg 320w, https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq3-sm.jpg 480w, https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq3-md.jpg 768w, https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq3-xl.jpg 1024w"></figure><p>Obviously the effect is best observed in motion.</p><div class="post__iframe"><iframe loading="lazy" width="560" height="314" src="https://www.youtube.com/embed/DvJ1bsjDpz4" allowfullscreen="allowfullscreen"></iframe></div><p>The video above shows the feedback working with different levels of persistence, it also shows some additional layering effects that are introduced between the background screen and the camera depending on the progress of the music. It is important to note that the whole process requires a secondary render camera. This is because if the system uses the primary camera for the feedback render then the resulting image will involve feedback of every visible element. By using a secondary camera specifically for the feedback image the game objects can be separated into layer-masks that appear in the feedback layer, the game layer or both.</p></article></div><p> </p></div><footer class="content__footer"><div class="content__last-updated">This article was updated on <time datetime="2025-10-05T10:14">Oct 5, 2025</time></div></footer></div></article><div class="content__section post__related"><div class="main__inner"><h3 class="content__section__title">Related post</h3><div class="post__related__wrap"><article class="c-card"><div class="c-card__meta"><div class="c-card__author"><a href="https://tomnullpointer.github.io/gh-pages/authors/me/">me</a></div><time datetime="2025-10-04T21:37">Oct 4, 2025 </time><a href="https://tomnullpointer.github.io/gh-pages/tags/game-development/" class="c-card-tag">Game Development</a></div><a href="https://tomnullpointer.github.io/gh-pages/game-jams-and-freebies.html" class="c-card__image"><img src="https://tomnullpointer.github.io/gh-pages/media/posts/14/2025-10-04-22_31_47-Publii-md.png" srcset="https://tomnullpointer.github.io/gh-pages/media/posts/14/responsive/2025-10-04-22_31_47-Publii-md-xs.png 320w, https://tomnullpointer.github.io/gh-pages/media/posts/14/responsive/2025-10-04-22_31_47-Publii-md-sm.png 480w" sizes="(min-width: 700px) 200px, (min-width: 480px) 160px, calc(100vw - 50px)" loading="lazy" height="445" width="721" alt=""></a><header class="c-card__header"><h2 class="c-card__title"><a href="https://tomnullpointer.github.io/gh-pages/game-jams-and-freebies.html">Game Jams and Freebies</a></h2><p>This is a short list of some of the side projects and&hellip;</p></header></article></div></div></div></main><div class="right-bar"><div class="right-bar__inner"><div class="sidebar"><section class="box featured"><h3 class="box__title">Featured Posts</h3><ul class="featured__container"><li class="featured__item"><a href="https://tomnullpointer.github.io/gh-pages/about-me-post.html" class="featured__image"><img src="https://tomnullpointer.github.io/gh-pages/media/posts/7/responsive/instapic-xs.png" loading="lazy" alt="" height="505" width="505"></a><div><a href="https://tomnullpointer.github.io/gh-pages/about-me-post.html" class="featured__title">About Me</a></div></li><li class="featured__item"><a href="https://tomnullpointer.github.io/gh-pages/about-my-academic-practice.html" class="featured__image"><img src="https://tomnullpointer.github.io/gh-pages/media/posts/9/responsive/mexico1-md-xs.jpg" loading="lazy" alt="" height="513" width="513"></a><div><a href="https://tomnullpointer.github.io/gh-pages/about-my-academic-practice.html" class="featured__title">Academic Practice</a></div></li><li class="featured__item"><a href="https://tomnullpointer.github.io/gh-pages/cv-bio.html" class="featured__image"><img src="https://tomnullpointer.github.io/gh-pages/media/posts/15/responsive/Bio-data-format-2-724x1024-3615278986-xs.jpg" loading="lazy" alt="" height="1024" width="1024"></a><div><a href="https://tomnullpointer.github.io/gh-pages/cv-bio.html" class="featured__title">C.V. Bio</a></div></li><li class="featured__item"><a href="https://tomnullpointer.github.io/gh-pages/nullpointer-games.html" class="featured__image"><img src="https://tomnullpointer.github.io/gh-pages/media/posts/8/responsive/ss_244d42e4eed84c0d5e1413914cb6bef2911d3300.1920x1080-md-xs.jpg" loading="lazy" alt="" height="432" width="432"></a><div><a href="https://tomnullpointer.github.io/gh-pages/nullpointer-games.html" class="featured__title">Commercial Games</a></div></li><li class="featured__item"><a href="https://tomnullpointer.github.io/gh-pages/game-jams-and-freebies.html" class="featured__image"><img src="https://tomnullpointer.github.io/gh-pages/media/posts/14/responsive/2025-10-04-22_31_47-Publii-md-xs.png" loading="lazy" alt="" height="445" width="445"></a><div><a href="https://tomnullpointer.github.io/gh-pages/game-jams-and-freebies.html" class="featured__title">Game Jams and Freebies</a></div></li></ul></section><section class="box tags"><h3 class="box__title">Recommended Topics</h3><ul class="tags__list"><li class="tags__item"><a href="https://tomnullpointer.github.io/gh-pages/tags/about/" class="btn btn--gray">About <sup>(4)</sup></a></li><li class="tags__item"><a href="https://tomnullpointer.github.io/gh-pages/tags/archive/" class="btn btn--gray">Archive <sup>(6)</sup></a></li><li class="tags__item"><a href="https://tomnullpointer.github.io/gh-pages/tags/explainer/" class="btn btn--gray">Explainer <sup>(6)</sup></a></li><li class="tags__item"><a href="https://tomnullpointer.github.io/gh-pages/tags/game-development/" class="btn btn--gray">Game Development <sup>(4)</sup></a></li><li class="tags__item"><a href="https://tomnullpointer.github.io/gh-pages/tags/installation-art/" class="btn btn--gray">Installation Art <sup>(1)</sup></a></li><li class="tags__item"><a href="https://tomnullpointer.github.io/gh-pages/tags/isosurfaces/" class="btn btn--gray">IsoSurfaces <sup>(3)</sup></a></li><li class="tags__item"><a href="https://tomnullpointer.github.io/gh-pages/tags/procedural-generation/" class="btn btn--gray">Procedural Generation <sup>(12)</sup></a></li></ul></section></div></div></div></div><script defer="defer" src="https://tomnullpointer.github.io/gh-pages/assets/js/scripts.min.js?v=b2d91bcadbf5db401b76eb5bb3092eb7"></script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>