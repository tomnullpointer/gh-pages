{
    "version": "https://jsonfeed.org/version/1",
    "title": "NULLPOINTER",
    "description": "",
    "home_page_url": "https://tomnullpointer.github.io/gh-pages",
    "feed_url": "https://tomnullpointer.github.io/gh-pages/feed.json",
    "user_comment": "",
    "author": {
        "name": "me"
    },
    "items": [
        {
            "id": "https://tomnullpointer.github.io/gh-pages/voxel-landscapes.html",
            "url": "https://tomnullpointer.github.io/gh-pages/voxel-landscapes.html",
            "title": "Voxel Landscapes",
            "summary": "I ahve always been interested in different methods of terrain generation, from&hellip;",
            "content_html": "<p>I ahve always been interested in different methods of terrain generation, from Geo-mipmaps to Cubspheres etc. One of the format I have worked the most with is probably noise-generated isosurfaces, wrapped with either a marching cubes algorithmn or an equivalent (Dual countouring, tetra etc)</p>\n<p>I have used different variations of isosurface generation in projects such as Permutation Racer, Procedural Planets and even a gpu shader version.</p>\n<p>Below is a short video of realtime generation via the graphics card and a small gallery of images from different iterations of my Terrain generation work.</p>\n<figure class=\"post__video\"><iframe loading=\"lazy\" width=\"560\" height=\"314\" src=\"https://www.youtube.com/embed/fh_xKB75LBU\" allowfullscreen=\"allowfullscreen\" data-mce-fragment=\"1\"></iframe></figure>\n<div class=\"gallery-wrapper\"><div class=\"gallery\"  data-is-empty=\"false\" data-translation=\"Add images\" data-columns=\"3\">\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/560198844714319873-B8Y53aoCAAAASS8.jpg\" data-size=\"1200x659\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/560198844714319873-B8Y53aoCAAAASS8-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"422\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/560200604916924419-B8Y7etdCcAAeB6L.jpg\" data-size=\"1200x645\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/560200604916924419-B8Y7etdCcAAeB6L-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"413\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/563845811214495746-B9MuwobCYAEejDn.jpg\" data-size=\"1200x649\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/563845811214495746-B9MuwobCYAEejDn-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"415\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/574587423247712257-B_lYNnCUIAAtHz0.jpg\" data-size=\"1200x681\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/574587423247712257-B_lYNnCUIAAtHz0-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"436\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/654032724219568128-CROXI4bWgAAtYxi.jpg\" data-size=\"1200x726\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/654032724219568128-CROXI4bWgAAtYxi-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"465\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/768556592631582720-Cqp2HmsWcAIbiqC.jpg\" data-size=\"1200x726\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/768556592631582720-Cqp2HmsWcAIbiqC-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"465\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/768566940910678016-Cqp_h2IWIAIx2cj.jpg\" data-size=\"1200x737\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/768566940910678016-Cqp_h2IWIAIx2cj-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"472\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/769652011985952768-Cq5aZ1xXgAAUuCd.jpg\" data-size=\"1200x698\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/769652011985952768-Cq5aZ1xXgAAUuCd-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"447\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/773274066941861889-Crs4pmXWEAEjQWC.jpg\" data-size=\"1200x702\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/773274066941861889-Crs4pmXWEAEjQWC-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"449\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/775100139295965184-CsG1dMPWgAA0vws.jpg\" data-size=\"1200x633\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/775100139295965184-CsG1dMPWgAA0vws-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"405\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/775100258820952064-CsG1j-ZWcAAQB5p.jpg\" data-size=\"1200x714\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/775100258820952064-CsG1j-ZWcAAQB5p-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"457\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/838510837706915840-C6L9JEYWMAEB8xO.jpg\" data-size=\"1200x714\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/838510837706915840-C6L9JEYWMAEB8xO-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"457\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/855756660941492224-C-BCFNLWsAApxIe.jpg\" data-size=\"1200x726\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/855756660941492224-C-BCFNLWsAApxIe-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"465\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/891366238617817088-DF7E1GUXoAAoxYI.jpg\" data-size=\"1200x686\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/891366238617817088-DF7E1GUXoAAoxYI-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"439\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/891406490237620224-DF7pVqHWAAAIaH2.jpg\" data-size=\"1200x678\"><img loading=\"lazy\" src=\"https://tomnullpointer.github.io/gh-pages/media/posts/19/gallery/891406490237620224-DF7pVqHWAAAIaH2-thumbnail.jpg\" alt=\"\" width=\"768\" height=\"434\"></a></figure>\n</div></div>\n<p> </p>\n<p> </p>\n<p> </p>\n<p> </p>\n<p> </p>\n<p> </p>\n<p> </p>\n<p> </p>\n<p> </p>\n<p> </p>\n<p> </p>\n<p> </p>\n<p> </p>",
            "image": "https://tomnullpointer.github.io/gh-pages/media/posts/19/838510837706915840-C6L9JEYWMAEB8xO-2.jpg",
            "author": {
                "name": "me"
            },
            "tags": [
                   "Procedural Generation",
                   "IsoSurfaces"
            ],
            "date_published": "2025-10-05T12:31:43+01:00",
            "date_modified": "2025-10-05T12:43:56+01:00"
        },
        {
            "id": "https://tomnullpointer.github.io/gh-pages/procedural-planetoids.html",
            "url": "https://tomnullpointer.github.io/gh-pages/procedural-planetoids.html",
            "title": "Procedural Planetoids",
            "summary": "Procedural Planetoids is a project I made for Procjam, a GameJam focused on&hellip;",
            "content_html": "<figure class=\"post__image\"><img  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/18/797447640019517440-CxEaX8QXEAA_c8d.jpg\" alt=\"\" width=\"304\" height=\"252\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/797447640019517440-CxEaX8QXEAA_c8d-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/797447640019517440-CxEaX8QXEAA_c8d-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/797447640019517440-CxEaX8QXEAA_c8d-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/797447640019517440-CxEaX8QXEAA_c8d-xl.jpg 1024w\"></figure><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/18/797448202689642497-CxEa54zXcAE8A88-2.jpg\" alt=\"\" width=\"305\" height=\"253\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/797448202689642497-CxEa54zXcAE8A88-2-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/797448202689642497-CxEa54zXcAE8A88-2-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/797448202689642497-CxEa54zXcAE8A88-2-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/797448202689642497-CxEa54zXcAE8A88-2-xl.jpg 1024w\"></figure>\n<p>Procedural Planetoids is a project I made for <a href=\"https://itch.io/jam/procjam\" rel=\"noopener\" target=\"_blank\">Procjam</a>, a GameJam focused on procedural generation. Its simple tool that generates voxel based planets, with a few parameters exposed to the user via sliders. </p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/18/FxuVE6.jpg\" alt=\"\" width=\"2048\" height=\"1152\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/FxuVE6-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/FxuVE6-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/FxuVE6-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/FxuVE6-xl.jpg 1024w\"></figure>\n<p>I used a marching cubes algorithmn to ‘skin’ an isosurface for the planet based on values from a noise array. The noise array is populated and ‘carved’ via a serioues of funcitons that are linked to the UI parameters, so you can make you plant more fragmented, smoother, or spikier etc. The final form is then textured with a spherical styled triplanar shader i wrote.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/18/797446880481382400-CxEZsI3WQAA4UPe.jpg\" alt=\"\" width=\"1175\" height=\"974\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/797446880481382400-CxEZsI3WQAA4UPe-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/797446880481382400-CxEZsI3WQAA4UPe-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/797446880481382400-CxEZsI3WQAA4UPe-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/18/responsive/797446880481382400-CxEZsI3WQAA4UPe-xl.jpg 1024w\"></figure>",
            "image": "https://tomnullpointer.github.io/gh-pages/media/posts/18/795773316317511680-CwsnlHAXAAAV6Ul.jpg",
            "author": {
                "name": "me"
            },
            "tags": [
                   "Procedural Generation",
                   "IsoSurfaces"
            ],
            "date_published": "2025-10-05T11:42:17+01:00",
            "date_modified": "2025-10-05T12:05:32+01:00"
        },
        {
            "id": "https://tomnullpointer.github.io/gh-pages/proc-gen-coral-reef.html",
            "url": "https://tomnullpointer.github.io/gh-pages/proc-gen-coral-reef.html",
            "title": "Proc Gen Coral Reef",
            "summary": "This project was an attempt to generate an entire 3D environment procedurally&hellip;",
            "content_html": "<p> </p>\n<figure class=\"post__image\"><img  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/17/ezgif-6b8b9332878fca.gif\" alt=\"\" width=\"327\" height=\"327\"></figure><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/17/ezgif-66bcfe3dba7c23-3.gif\" alt=\"\" width=\"328\" height=\"328\"></figure>\n<p>This project was an attempt to generate an entire 3D environment procedurally (down to mesh level).</p>\n<p>The coral reef in these images consists of generated, terrain, fish, jellyfish, coral plants and visual effects, all of which are built on the fly by code.</p>\n<p>Each coral plant is constructed from a virtual skeleton via a custom node system (similar to L-Systems but my own design). </p>\n<figure class=\"post__image\"><img  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/17/ezgif-5-be5672580e82-2.gif\" alt=\"\" width=\"320\" height=\"320\"></figure><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/17/ezgif-5-fe0e29aa526a-2.gif\" alt=\"\" width=\"320\" height=\"320\"></figure>\n<p>These skeletons are then clad with procedurally generated meshes and mapped with generated palette colors.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/17/1132283914490392576-D7auNYjXkAAonGe.jpg\" alt=\"\" width=\"1102\" height=\"786\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/17/responsive/1132283914490392576-D7auNYjXkAAonGe-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/17/responsive/1132283914490392576-D7auNYjXkAAonGe-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/17/responsive/1132283914490392576-D7auNYjXkAAonGe-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/17/responsive/1132283914490392576-D7auNYjXkAAonGe-xl.jpg 1024w\"></figure>\n<p>The fish &amp; jellyfish are also generated in real-time from code-constructed meshes. Their movement across the reef is directed by boid flocking algorithmns and the mesh animations are driven by a suit of  vertex shaders i wrote specifically for the purpose.</p>\n<figure class=\"post__image\"><img  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/17/ezgif-6c41583c53f122-2.gif\" alt=\"\" width=\"293\" height=\"219\"></figure><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/17/ezgif-6ed9906eeca2b7.gif\" alt=\"\" width=\"349\" height=\"218\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/17/976875237118742529-DY6O1rsW0AMyB71-2.jpg\" alt=\"\" width=\"1200\" height=\"1200\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/17/responsive/976875237118742529-DY6O1rsW0AMyB71-2-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/17/responsive/976875237118742529-DY6O1rsW0AMyB71-2-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/17/responsive/976875237118742529-DY6O1rsW0AMyB71-2-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/17/responsive/976875237118742529-DY6O1rsW0AMyB71-2-xl.jpg 1024w\"></figure>",
            "image": "https://tomnullpointer.github.io/gh-pages/media/posts/17/ezgif-5-be5672580e82-3.gif",
            "author": {
                "name": "me"
            },
            "tags": [
                   "Procedural Generation"
            ],
            "date_published": "2025-10-05T11:25:30+01:00",
            "date_modified": "2025-10-05T11:36:30+01:00"
        },
        {
            "id": "https://tomnullpointer.github.io/gh-pages/generating-procedural-insects-with-ik.html",
            "url": "https://tomnullpointer.github.io/gh-pages/generating-procedural-insects-with-ik.html",
            "title": "Generating procedural Insects with IK",
            "summary": "This project was an experiment in generating insect models from procedural meshes&hellip;",
            "content_html": "<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/16/ezgif-5-d0776e5c1743.gif\" alt=\"\" width=\"504\" height=\"252\"></figure>\n<p>This project was an experiment in generating insect models from procedural meshes while using IK Physics to allow the resulting structures to have procedurally animated walks.</p>\n<p>The body parts (leg parts, wings, antennae etc) of each insect are generated according to a variable ruleset which determines the orientation, scaling and connectivity limits. The insect is then assembled from meshes which are themselves procedurally generated with a series of 3d modifiers (warps, twists, tapers etc).</p>\n<p>Finally the meshes are tinted with a vertex colour palette that uses local triplanar space to blend between gradients.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/16/2insects.jpg\" alt=\"\" width=\"1479\" height=\"705\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/16/responsive/2insects-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/16/responsive/2insects-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/16/responsive/2insects-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/16/responsive/2insects-xl.jpg 1024w\"></figure>\n<p>The elements of the skeleton are dynamically bound to a generated IK rig which runs various motors in order to procedurally animate the insects walk.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/16/ezgif-5-94f2774302ca.gif\" alt=\"\" width=\"504\" height=\"252\"></figure>\n<p>The system is capable of generating a wide range of insects that both look unique and have varying movement styles</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/16/1132287297876123649-D7axQUMWwAA55MW-2.jpg\" alt=\"\" width=\"1200\" height=\"1200\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/16/responsive/1132287297876123649-D7axQUMWwAA55MW-2-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/16/responsive/1132287297876123649-D7axQUMWwAA55MW-2-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/16/responsive/1132287297876123649-D7axQUMWwAA55MW-2-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/16/responsive/1132287297876123649-D7axQUMWwAA55MW-2-xl.jpg 1024w\"></figure>",
            "image": "https://tomnullpointer.github.io/gh-pages/media/posts/16/1109928671727501312-D2dCOU0WoAYCyVa-2.png",
            "author": {
                "name": "me"
            },
            "tags": [
                   "Procedural Generation"
            ],
            "date_published": "2025-10-05T11:20:19+01:00",
            "date_modified": "2025-10-05T11:20:19+01:00"
        },
        {
            "id": "https://tomnullpointer.github.io/gh-pages/cv-bio.html",
            "url": "https://tomnullpointer.github.io/gh-pages/cv-bio.html",
            "title": "C.V. Bio",
            "summary": "Employment Nullpointer Ltd [Brighton] 2000 – present Director Responsible for the development&hellip;",
            "content_html": "<h2>Employment</h2>\n<p><strong>Nullpointer Ltd </strong>[Brighton] 2000 – present<br><em>Director</em><br>Responsible for the development and direction of a creative digital<br>studio that has exhibited internationally, produced multiple game titles<br>and worked for clients such as Tate, the V&amp;A and The Southbank Centre.</p>\n<p><br><strong>Big Robot Ltd  </strong>[Brighton/Bristol] 2011 – 2020<br><em>Lead Programmer</em><br>Responsible for directing and implementing code/design for four<br>commercial games.</p>\n<p><strong>Hudderfield University</strong> [Huddersfield] 2010 – 2015<br><em>Lecturer</em><br>Responsible for: BA/BSC Digital Culture module, Foundation games<br>programming modules, MA digital design tutor, BA<br>Animation/VR/Digital design tutor.</p>\n<h2>Education</h2>\n<p><strong>Hudderfield University</strong> [Huddersfield] 2010 – 2015<br><em>Phd </em><br>“An investigation of the digital sublime in videogames”<br>Practice based Phd involving software development and thesis.</p>\n<p><strong>Goldsmiths College</strong> [London] 1992 – 1995<br>BA Art History and Studio Practice.</p>\n<h2>Experience</h2>\n<p>I have over 25 years of design and programming experience, producing client driven projects, teaching game design at University level and creating cutting edge game-projects for Phd research. I work mainly in Unity, but I also have experience of working with c++, openframeworks, developing for IOS &amp; Android platforms, Xbox consoles and Nintendo Switch.</p>\n<p>I have worked on many aspects of design and programming including; AI, UI, UX, level design, VFX, sound design, game mechanics, physics, animation, shaders. I often work as a solo developer, but I am also used to working in teams, directing art/sound/animation, defining additional programming, managing production, workflow, testing, releases and repositories.</p>\n<p>I have run my own Limited Company for over a decade and have created 7 commercial games, working with publishers and other partners. I have also produced work for museums and galleries like the Tate, Southbank, Design Museum and V&amp;A.</p>\n<p>I have given presentations about creative coding and game design at various international venues including GDC (San Francisco), Indievelopment (Amsterdam), Rezzed (UK). I have a Phd in philosophy &amp; game design and have a specific interest in procedural generation and generative art.</p>\n<p> </p>",
            "image": "https://tomnullpointer.github.io/gh-pages/media/posts/15/Bio-data-format-2-724x1024-3615278986.jpg",
            "author": {
                "name": "me"
            },
            "tags": [
                   "About"
            ],
            "date_published": "2025-10-04T21:40:47+01:00",
            "date_modified": "2025-10-05T10:15:15+01:00"
        },
        {
            "id": "https://tomnullpointer.github.io/gh-pages/game-jams-and-freebies.html",
            "url": "https://tomnullpointer.github.io/gh-pages/game-jams-and-freebies.html",
            "title": "Game Jams and Freebies",
            "summary": "This is a short list of some of the side projects and&hellip;",
            "content_html": "<figure>This is a short list of some of the side projects and game jam contributions I have produced over the years. A full list is available on my <a href=\"https://tomnullpointer.itch.io/\" target=\"_blank\" rel=\"noopener noreferrer\">itch.io page</a>.</figure>\n<h2><a href=\"https://tomnullpointer.itch.io/jeliens\" target=\"_blank\" rel=\"noopener noreferrer\">Jeliens</a><br><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/14/2025-10-04-22_31_47-Publii.png\" alt=\"\" width=\"721\" height=\"445\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/14/responsive/2025-10-04-22_31_47-Publii-xs.png 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/14/responsive/2025-10-04-22_31_47-Publii-sm.png 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/14/responsive/2025-10-04-22_31_47-Publii-md.png 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/14/responsive/2025-10-04-22_31_47-Publii-xl.png 1024w\"></figure></h2>\n<p>A Jellyfish generator developed for ProcJam2019. It uses realtie mesh generation and shader based animations to create a range of alien jellyfish (Web Player)</p>\n<h2><a href=\"https://tomnullpointer.itch.io/procjam21\" target=\"_blank\" rel=\"noopener noreferrer\">Fantasy Map Generator</a></h2>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/14/2025-10-04-22_25_23-Settings.png\" alt=\"\" width=\"1102\" height=\"852\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/14/responsive/2025-10-04-22_25_23-Settings-xs.png 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/14/responsive/2025-10-04-22_25_23-Settings-sm.png 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/14/responsive/2025-10-04-22_25_23-Settings-md.png 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/14/responsive/2025-10-04-22_25_23-Settings-xl.png 1024w\"></figure>\n<figure>A map generator developed for ProcJam2021, intended to create maps in the style of old fantasy books. It uses a combination of Vornoi cell generation, pathfinding and biome logic to define a Tolkein-esque landscape. The user can adjust various parameters to explore the possibility space of the model. (Web Player)</figure>\n<h2><a href=\"https://tomnullpointer.itch.io/permutation-racer\" rel=\"noopener\" target=\"_blank\">Permutation Racer</a><div class=\"post__iframe\"><iframe loading=\"lazy\" width=\"560\" height=\"314\" src=\"https://www.youtube.com/embed/nvVdMr6ox9A\" allowfullscreen=\"allowfullscreen\" data-mce-fragment=\"1\"></iframe></div><a href=\"https://tomnullpointer.itch.io/permutation-racer\" rel=\"noopener\" target=\"_blank\"></a></h2>\n<figure></figure>\n<p>Permutation Racer’ is an experimental, endless racing game, exploring the procedural construction of space.</p>\n<p>It’s part of my PHD research to investigate ideas that connect games, permutation and the sublime. The race track is generated from a series of noise filtered ‘biome’ styling functions. There are about 12 region types ranging from chasms to archways and caves, all generated in real time as the player progresses. I might post a more technical article about the actual methods used later. The only aim is to travel as far as possible, hampered by the fact that over time/distance the generation algorithms make the track more hazardous and convoluted.</p>\n<h2><a href=\"https://tomnullpointer.itch.io/in-ruins\" rel=\"noopener\" target=\"_blank\">In Ruins</a></h2>\n<p><img loading=\"lazy\" src=\"https://img.itch.zone/aW1hZ2UvNDk1NDQvMjE3MDA0LmpwZw==/original/mGvqB%2F.jpg\" alt=\"screenshot\" width=\"100%\" data-is-external-image=\"true\"></p>\n<p>‘In Ruins’ is an experimental, ambient game examining the procedural construction of space. It’s part of an ongoing Phd research project to investigate ideas that connect games, permutation and the sublime. It’s part of a series of games inspired by artistic interpretations of the sublime, in this case the work of Romantic landscape painters (Thomas Cole, Caspar David Friedrich etc). Its also heavily influenced by Fumito Uedas Ico series.</p>\n<p>The player is deposited on the edge of a procedurally generated island. The island consists of overgrown pathways ruined spires and broken ramparts. A central tower looms above the island beckoning the player towards it.</p>",
            "image": "https://tomnullpointer.github.io/gh-pages/media/posts/14/2025-10-04-22_31_47-Publii-md.png",
            "author": {
                "name": "me"
            },
            "tags": [
                   "Procedural Generation",
                   "Game Development"
            ],
            "date_published": "2025-10-04T21:37:42+01:00",
            "date_modified": "2025-10-05T10:11:11+01:00"
        },
        {
            "id": "https://tomnullpointer.github.io/gh-pages/coding-a-generative-music-game-avseq.html",
            "url": "https://tomnullpointer.github.io/gh-pages/coding-a-generative-music-game-avseq.html",
            "title": "Coding a generative music game – AvSeq",
            "summary": "This post outlines some of the technical issues and solutions connected with&hellip;",
            "content_html": "<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/13/ResHubAvseq1.jpg\" alt=\"\" width=\"910\" height=\"400\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq1-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq1-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq1-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq1-xl.jpg 1024w\"></figure>\n<p><br><br></p>\n<div class=\"entry-content\">\n<article>\n<p>This post outlines some of the technical issues and solutions connected with the development of AvSeq, the first game produced for my PhD research. More generalised information about the game is available <a href=\"http://www.nullpointer.co.uk/content/avseq-3/\">here</a></p>\n<h2>Accurate high frequency audio timing and quantization in Unity</h2>\n<p>During the development of AvSeq I needed to find a way to get a high accuracy audiotimer to trigger audiovisual events in perfect synchronization. Unity is primarily a games engine and had not built-in functionality to support this type of requirement. In libraries like portaudio the code provides a callback function that can deliver buffered content to the soundcard, down to the level of a single sample. In Unity the update threads run at a much slower rate and cant be used for reliable timing. Unity also discourages the use of threads and out-of-update callbacks so I had to find another way. The solution I came up with was to leverage the built in functions of the packaged FMOD library. I particular this library provides functions to<br>grab the current playpoint of a sample and also trigger a sample with a specific pre-roll delay.<br>I used these features in the following steps.</p>\n<ol>\n<li>Setup and play a hardware looping metronome via FMOD. This can be a standard clicktrack sample or even a silent audiofile. The length and playback pitch of the file represents a single audio-beat cycle that can be tracked in code.</li>\n<li>Run a FixedUpdate (or any fast thread) and within this request the the current PCM sample position of the metronome.</li>\n<li>Use this position to detect if the current loop of the metronome sample is nearing its end. The margin of error for this ‘catching’ process detect depends on the frequency of your update and the pitch/frequency of the metronome.</li>\n<li>If the retrieved PCM location is close enough to the next loop point then trigger a new sound to play BUT set the new sample pre-roll to the remaining samples in the current loop (loop sample length- current sample position).</li>\n<li>Don’t create or run any further triggers until the retrieved position has looped back over the zero-point.<em><br></em></li>\n</ol>\n<p>This system allows accuracy up until a relatively high tempo rate (dependent on individual machine speed), and allows the sample accurate triggering and quantizing of triggered audiosources. The tempo of the entire system can be adjusted by varying the playback pitch of the reference metronome, for example a metronome sample of 1 second length, will define a bpm of 60. At double the metronome pitch the bpm will be 120. The ‘catch’ margin can be adjusted dynamically as a percentage of this overall length if you want real-time pitch changes like I use in AvSeq. In AvSeq I also use the looping reference sample to keep track of beats/bars in the total sequence and each new beat trigger the playback of samples assigned to that beat in the sequencer score.</p>\n<p>Some example code:</p>\n<pre>\tvoid FixedUpdate () {\n\n\t\tm_MS=m_ASMetronome.timeSamples;//get the current position of the looping reference sample\n\t\tuint catchup=0;\n\t\tfloat delay=0;\n\n\t\tif(m_MS&lt;m_CatchMargin &amp;&amp; m_HasLooped==1)//check to see if the reference sample has looped and has been dealt with\n\t\t{\n\t\t\tm_HasLooped=0;//reset the haslooped indicator\n\t\t}\n\n\t\t//catch end of loop\n\t\tif(m_MS&gt;m_SampleLength-m_CatchMargin)\n\t\t{\n\t\t\tm_MSCatch=m_MS;\n\n\t\t\t//only do if we havent marked a new loop yet\n\t\t\tif(m_HasLooped==0)\n\t\t\t{\n\t\t\tcatchup=(uint)(m_SampleLength-m_MS);\t//work out how long to delay the start of any new sample\n\t\t\tm_HasLooped=1;\t//register that we have dealt with the current loop\n\t\t\tm_AudioSource.Play(catchup);//play a sample with the correct delay to coincide with the actual loop point\n\t\t\t}\n\t\t}\n              }\n</pre>\n<p>There’s a bit more discussion and some extensions of the technique discussed at <a href=\"http://forum.unity3d.com/threads/audio-stepsequencer-and-they-said-it-couldnt-be-done.78003/\">http://forum.unity3d.com/threads/audio-stepsequencer-and-they-said-it-couldnt-be-done.78003/</a> </p>\n<h2>Video Feedback effect in Unity</h2>\n<p>I wanted AvSeq to feature some form of video feedback, discovered in camera/tv loop experiments of the 1980s. You can see the effect in this video <a href=\"https://www.youtube.com/watch?v=eD9rr0gTLSU\">https://www.youtube.com/watch?v=eD9rr0gTLSU</a> (although its a recent video, the actual technique is the same). To achieve this I mimicked the feedback loop by rendering a subset of the games geometry to an offscreen surface and then drawing that image in the background of the scene. This meant that each frame of gameplay also had a degree of the previous frame set behind the current objects. By altering the transparency of the previous frame image the system can control the amount of feedback and blur that occurs. The scene setup for this process is show below.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/13/ResHubAvseq2.jpg\" alt=\"\" width=\"1448\" height=\"680\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq2-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq2-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq2-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq2-xl.jpg 1024w\"></figure>\n<ul>\n<li>A: Shows the scene from a point close to the player perspective, but with the camera pulled back slightly to show the edges of the background screen. The image shows the foreground cubes and their after-images on the background screen (one cube is even passing through the background screen)</li>\n<li><br>B: Shows the positioning of the background screen and the ‘invisible’ offscreen rendering camera. The cubes can easily be seen in front of the screen, within the normal playspace of the game.</li>\n<li><br>C: shows the image viewed from the offscreen rendering camera. This image is then drawn onto the background screen during the next frame.</li>\n</ul>\n<p>Some compensation has to be made to account for offscreen texture surfaces being square and the scene view being landscape, but these are trivial ratio adjustments. In AvSeq I used additive blending on the background screen, in order to control the persistence of each frame and its feedback, but other blending methods can be used to generate more radical effects. Similarly the polygon mesh of the background plane can be warped to force the feedback to flow in a specific direction. Although I avoided extreme warping in the final game version, some of the prototypes demonstrate the effect more clearly.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/13/ResHubAvseq3.jpg\" alt=\"\" width=\"912\" height=\"412\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq3-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq3-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq3-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/13/responsive/ResHubAvseq3-xl.jpg 1024w\"></figure>\n<p>Obviously the effect is best observed in motion.</p>\n<div class=\"post__iframe\"><iframe loading=\"lazy\" width=\"560\" height=\"314\" src=\"https://www.youtube.com/embed/DvJ1bsjDpz4\" allowfullscreen=\"allowfullscreen\"></iframe></div>\n<p>The video above shows the feedback working with different levels of persistence, it also shows some additional layering effects that are introduced between the background screen and the camera depending on the progress of the music. It is important to note that the whole process requires a secondary render camera. This is because if the system uses the primary camera for the feedback render then the resulting image will involve feedback of every visible element. By using a secondary camera specifically for the feedback image the game objects can be separated into layer-masks that appear in the feedback layer, the game layer or both.</p>\n</article>\n</div>\n<p> </p>",
            "image": "https://tomnullpointer.github.io/gh-pages/media/posts/13/ss_907cc5a3b4478e531440c45cb9d84e1485734d43.1920x1080.jpg",
            "author": {
                "name": "me"
            },
            "tags": [
                   "Procedural Generation",
                   "Game Development",
                   "Explainer",
                   "Archive"
            ],
            "date_published": "2025-10-04T19:18:54+01:00",
            "date_modified": "2025-10-05T10:14:16+01:00"
        },
        {
            "id": "https://tomnullpointer.github.io/gh-pages/castle-generation-in-ruins.html",
            "url": "https://tomnullpointer.github.io/gh-pages/castle-generation-in-ruins.html",
            "title": "Castle generation – In Ruins",
            "summary": "This post outlines some of the technical issues and solutions connected with&hellip;",
            "content_html": "<div class=\"entry-header\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/ResHubInRuins1.jpg\" alt=\"\" width=\"912\" height=\"398\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins1-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins1-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins1-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins1-xl.jpg 1024w\"></figure>\n</div>\n<div class=\"entry-container\">\n<div class=\"entry-content\">\n<article>\n<p>This post outlines some of the technical issues and solutions connected with the development of In Ruins, the second game produced for my PhD research.</p>\n<p>In Ruins is an ambient exploration game with simple platforming and power up mechanics. It’s based on a small island of ruined castle walls and crumbling towers. This environment is procedurally generated using an extension of some traditional rogue-like dungeon generation techniques. More generalised information about the game and a download of the software is <a href=\"https://tomnullpointer.itch.io/in-ruins\">available at this link</a>. A description of the approach developed for In Ruins is outlined below.</p>\n<h2>2D Dungeon-like world generation stage</h2>\n<p>Although the world of In Ruins is 3D the architectural blueprint is based on a 2D floorplan generator. This generator can produce a range of layouts as illustrated below.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/ResHubInRuins3.jpg\" alt=\"\" width=\"908\" height=\"803\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins3-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins3-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins3-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins3-xl.jpg 1024w\"></figure>\n<p>The generator is based on some of the ideas outlined in the <a href=\"http://donjon.bin.sh/d20/dungeon/\">d20 Random Dungeon Generator</a> and operates in the following manner.</p>\n<ul>\n<li> A world definition dictates the number of desired ‘rooms’ and the range of dimensions (width/height) of those rooms. This definition also describes the overall dimension of the world, which is used to build a 2d array grid that is used for the placement and arrangement of rooms, corridors and doorways. The definition allows for ranges of variation in parameters such as room size, corridor length and floor height.</li>\n<li>A function AddRooms() attempts to place the desired number of rooms into the total base grid. There are a few placement routines that allow symmetrical layouts, sparse layouts, linear and constrained layouts etc. Each routine checks the validity of any newly placed room against the location of all previously placed rooms (checking for the intersection of walls and floor areas). The placement functions also ensure that there is sufficient space between rooms to allow for corridors and to avoid walls overlapping to double thickness. This is achieved by trapping all the placement locations and room dimensions to EVEN co-ordinates and room dimensions to ODD sizes. This ensures that the connections between rooms will line up correctly. When placing rooms in the grid the algorithm marks individual cells in the interiors as room tiles and those on the perimeter as wall tiles. This helps when checking the validity of subsequent room placements and also helps when locating doorways. Whne a room is placed it is recorded in a list, storing its ID, its x,y location and its</li>\n<li>A function AddExits() places a number of exits in the wall perimeter of a room, it uses the centre-point and dimensions recorded for a room to calculate the location of potential exits which are then checked against the grid to see if the cells are currently marked as walls. If the exit is valid then the cell is marked as a doorway in the master grid.</li>\n<li>The system then executes the AddCorridors() function. This steps through the master grid and whenever it encounters a cell marked as a doorway it attempts to ‘grow’ a corridor. The corridors are made by placing corridor tiles in a series of spans, starting at the discovered exit. Each span is of 2 cells length, to ensure it remains on the correct odd/even spacing and will connect to other doors. The corridors are then recursively generated from the endpoint of the last span. There is a chance for corridors to change direction or split at the end of any span. The probability of this is controlled by a series of variables in the general world definition.</li>\n</ul>\n<p>The image below demonstrates these features as follows: empty grid cells are black, corridors are white, room outer walls are red, doorways are green and the interior of each room is assigned a random colour. Door cells also indicate their exit direction, n,s,e,w and interior room cells also store their unique id. This allows later functions to decorate or alter each room specifically. A webplayer of this prototype is available <a href=\"http://www.nullpointer.co.uk/unity/rogue/WebPlayer.html\">here </a>to demonstrate the algorithms.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/rogue2d.jpg\" alt=\"\" width=\"596\" height=\"448\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/rogue2d-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/rogue2d-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/rogue2d-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/rogue2d-xl.jpg 1024w\"></figure>\n<p>5. The system then extends this 2D floorplan by assigning floor heights to each room. The corridor cells also have height levels that are adjusted dependent on the room heights that they connect to. The corridor heights are modified in a recursive process that creates stairs between connected room of different heights. The plan is then used to generate a 3D ‘maze’. Rather than rooms being enclosed as they would be in a traditional rogue-like, each room is treated as a plateau. This leads to the construction of spaces like the one in the image below. </p>\n<h2>3D Extension to the generation</h2>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/rogue3d3.jpg\" alt=\"\" width=\"794\" height=\"596\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/rogue3d3-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/rogue3d3-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/rogue3d3-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/rogue3d3-xl.jpg 1024w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/ResHubInRuins4-2.jpg\" alt=\"\" width=\"904\" height=\"800\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins4-2-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins4-2-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins4-2-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins4-2-xl.jpg 1024w\"></figure>\n<p>The construction process of the 3D version was then extended with the placement of various prop items and the variation of block forms.</p>\n<p>The range of styles possible is quite large, as indicated in the following images.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/ResHubInRuins3-2.jpg\" alt=\"\" width=\"908\" height=\"803\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins3-2-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins3-2-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins3-2-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins3-2-xl.jpg 1024w\"></figure>\n<p>To ensure that the resulting 3D model is graphically efficient the code that constructs the world from the floorplan calculates the neighbours for each cell and selects a 3D block that connects appropriately to adjacent cells. The image below shows the 16 blocks designed for all the possible connections in a Von Neumann neighbourhood. A good explanation of how this technique works for traditional tile games can be found <a href=\"http://www.angryfishstudios.com/2011/04/adventures-in-bitmasking/\">here</a>.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/ResHubInRuins5.jpg\" alt=\"\" width=\"712\" height=\"271\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins5-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins5-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins5-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins5-xl.jpg 1024w\"></figure>\n<p>The mesh construction could be done procedurally, but by using a Look-Up table of prefab forms the code can substitute alternatives to create a more varied and organic look. A selection of three cube forms and their variations is illustrated below. The cubes themselves are also textured procedurally, using a custom tri-planar mapping technique. This means that however tall the individual columns become the texturing on the will not stretch or deform. This shader technique will be covered in a future post.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/ResHubInRuins6.jpg\" alt=\"\" width=\"684\" height=\"256\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins6-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins6-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins6-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/12/responsive/ResHubInRuins6-xl.jpg 1024w\"></figure>\n<p>The final stage of generation involves dropping pre-designed tree models and grass prefabs onto the geometry. This is done by selecting a room from the list of those placed and then positioning the items within the rooms dimension and at the height the room is set to. This process could also be used to place specific items in specific rooms or place objects adjacent to walls or doors.</p>\n</article>\n</div>\n</div>",
            "image": "https://tomnullpointer.github.io/gh-pages/media/posts/12/ResHubInRuins4.jpg",
            "author": {
                "name": "me"
            },
            "tags": [
                   "Procedural Generation",
                   "Game Development",
                   "Explainer",
                   "Archive"
            ],
            "date_published": "2025-10-04T19:15:52+01:00",
            "date_modified": "2025-10-05T10:22:10+01:00"
        },
        {
            "id": "https://tomnullpointer.github.io/gh-pages/infinite-racetracks-permutation-racer.html",
            "url": "https://tomnullpointer.github.io/gh-pages/infinite-racetracks-permutation-racer.html",
            "title": "Infinite Racetracks – Permutation Racer",
            "summary": "This post outlines some of the technical issues and solutions connected with&hellip;",
            "content_html": "<div class=\"entry-header\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/ResHubPerm1.jpg\" alt=\"\" width=\"1819\" height=\"798\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm1-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm1-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm1-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm1-xl.jpg 1024w\"></figure>\n</div>\n<div class=\"entry-container\">\n<div class=\"entry-content\">\n<article>\n<p>This post outlines some of the technical issues and solutions connected with the development of Permutation Racer, the third game produced for my PhD research.</p>\n<p>Permutation Racer is an experimental, endless racing game, exploring the procedural construction of space.<br>It’s part of an ongoing investigation of ideas that connect games, permutation and the sublime. The race track is generated from a series of noise filtered ‘biome’ styling functions. There are about 12 region types ranging from chasms to archways and caves, all generated in real time as the player progresses. The objective is simply to travel as far as possible. More generalised information about the game and a download of the software is <a href=\"https://tomnullpointer.itch.io/permutation-racer\">available at this link</a>. A description of the approach developed for Permutation Racer is outlined below.</p>\n<h2>Endless Voxel Track</h2>\n<p>Permutation Racer uses Voxel Isosurfaces to produce its endless tracks. This technique is based on the marching cubes algorithm, a process which transforms a 3d array of density points into a polygonised mesh. There is some good documentation of this technique available <a href=\"http://paulbourke.net/geometry/polygonise/\">here</a>. In short these polygonising algorithms take an array of density values, like a point cloud and traverse the array in voxels, marking the points where the density values shift from interior to exterior values. The difference between ‘inside’ and ‘outside’ is defined as a threshold value, usually between 0 and 1 (though this can be -1 to +1 depending on the density values used). The threshold value dictates the point in a density spectrum where the voxel ‘skin’ lies. For example, if the threshold value was .1 the following string of numbers would be skinned as a small hill-like curve .2 .3 .4 .5 .4 .3 .2. If the threshold was raised to .6 nothing would be polgonised as all the density values are under the threshold. A solidity threshold closer to 0 leads to ‘fuller’ forms whereas a higher values result in a more sparse voxel space. Since Permutation Racer uses a mathematical noise field (simplex) to provide the underlying density values, increasing the frequency of the noise function will also effect the size and number of voxelised ‘blobs’ polygonised in a chunk. The image below demonstrates the sort of effects these parameters can have (density threshold on the y-axis and frequency of noise on the x-axis).</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/VoxelCubes.jpg\" alt=\"\" width=\"769\" height=\"741\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/VoxelCubes-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/VoxelCubes-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/VoxelCubes-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/VoxelCubes-xl.jpg 1024w\"></figure>\n<p>The resolution of the voxel grid is entirely down to the requirements of the game, but a more detailed resolution and larger volume will obviously take longer to calculate. The process of voxelisation is therefore best seperated into individual chunks, so that the game world can be defined/polygonised/rendered/culled on threads. In Permutation Racer each chunk of world consists of a cubic volume containing x=22,z=22,y=16 voxels. The resolution of the resulting mesh can be seen in the chunks below.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/ResHubPerm4.jpg\" alt=\"\" width=\"1420\" height=\"642\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm4-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm4-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm4-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm4-xl.jpg 1024w\"></figure>\n<p>These chunks are processed in threads and positioned in the game scene in a linear path to build the racetrack. The image below demonstrates a range of individual chunks, produced from different underlying point cloud data.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/ResHubPerm2.jpg\" alt=\"\" width=\"724\" height=\"262\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm2-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm2-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm2-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm2-xl.jpg 1024w\"></figure>\n<p>In the actual game the adjacent chunks that make up the racertrack polygonise adjoining areas of the density array so that chunks remain continuous and readable.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/ResHubPerm5.jpg\" alt=\"\" width=\"1144\" height=\"620\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm5-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm5-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm5-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm5-xl.jpg 1024w\"></figure>\n<p>The image below shows a long section of track, click <a href=\"http://www.nullpointer.co.uk/images/testrack.gif\">here </a>to open the image and zoom in to see the details</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/testrack.gif\" alt=\"\" width=\"7376\" height=\"4664\"></figure>\n<br>\n<h2>Noise to Signal</h2>\n<p>As with all procedural generation the key to making the resulting world interesting is making the underlying structure interesting. The image of voxel cubes earlier in this post demonstrates the sort of features a simple noise field can create. However, the results are very chaotic and don’t feel organic or purposeful. Players generally enjoy exploring worlds that appear to have either history and purpose, and seem to have been created though geological processes or human intervention. Permutation Racer uses a series of synthesis approaches to generate interesting underlying data forms. These synthesis techniques are primarily based on the layering and filtering of fractal noise. In fact the term synthesis neatly references the approach of musical synthesizers which use similar techniques to layer waveforms into richer and more interesting sound forms. This process is illustrated below (courtesy of http://www.planetoftunes.com/,https://documentation.apple.com/en/logicpro/)</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/synthesis.jpg\" alt=\"\" width=\"789\" height=\"253\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/synthesis-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/synthesis-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/synthesis-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/synthesis-xl.jpg 1024w\"></figure>\n<p>There are many types of synthesis, additive (shown above left) , subtractive and FM (frequency modulation,shown above right). Permutation Racer uses all of these techniques, but applies them to the output of noise functions rather than waveforms. Noise functions (simplex/perlin etc don’t have periodic cycles, but can be smoothed and produced at varying frequencies). The way these functions are layered gives the resulting forms specific characteristics. In Permutation Racer noise layers are modulated by each other and by other mathematical processes such as sinewaves and rounding functions. The image below demonstrates how the main track uses a combined sinewave function to produce the curves in the racetrack. The distortion or ‘curviness’ of the track is increased along the x axis, where the x-value in world space is used to multiply a secondary waveform that distorts the original sinewave (see the FM example above).</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/ResHubPerm6.jpg\" alt=\"\" width=\"789\" height=\"253\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm6-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm6-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm6-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm6-xl.jpg 1024w\"></figure>\n<p>This function is calculated for every x,y,z point requested by the polygonising algorithm. Instead for returning unmodified noise, the program returns a noisefield that is modified by many attributes, all of which are based on the spatial location of the request. For example, the GetNoise(x,y,z) function will return 1 for all points that are outside the current sine centre plus a margin amount. This causes the track to follow the sinewave curve and have cliff-walls at its sides. The width of the track is then controllable with the margin variable, which itself can be linked to x distance and other noise function. The GetNoise() function might also introduce increasing amounts of random noise as the y-axis rises over a specific ceiling. This will cause spikes and undulations to form a ceiling over the track. Its the development and combination of these filters that allows the engine to produce interesting geometry.</p>\n<p>Permutation Racer contains a library of GetNoise() functions that produce different terrain; forests, tunnels, corridors, causeways. In fact the game simultaneously calculates two types at all times and interpolates the results before passing the final value back to the polgonising algorithm. This allows the gameworld to blend between different terrain forms as the player progresses. The image below (from an early prototype) shows a forest generation function (left) mixed with a cave generation function (Right).</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/ResHubPerm7.jpg\" alt=\"\" width=\"878\" height=\"190\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm7-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm7-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm7-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm7-xl.jpg 1024w\"></figure>\n<p>It only takes a few modifications to use the techniques discussed above for generating a wide range of different game worlds, even spherical ones!</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/ResHubPerm8.jpg\" alt=\"\" width=\"944\" height=\"588\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm8-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm8-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm8-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/11/responsive/ResHubPerm8-xl.jpg 1024w\"></figure>\n</article>\n</div>\n</div>",
            "image": "https://tomnullpointer.github.io/gh-pages/media/posts/11/ResHubPerm5-2.jpg",
            "author": {
                "name": "me"
            },
            "tags": [
                   "Procedural Generation",
                   "IsoSurfaces",
                   "Game Development",
                   "Explainer",
                   "Archive"
            ],
            "date_published": "2025-10-04T19:09:35+01:00",
            "date_modified": "2025-10-05T12:05:43+01:00"
        },
        {
            "id": "https://tomnullpointer.github.io/gh-pages/installation-art.html",
            "url": "https://tomnullpointer.github.io/gh-pages/installation-art.html",
            "title": "Installation Art",
            "summary": "I have worked on a range of installations and interactives for galleries,&hellip;",
            "content_html": "<div class=\"entry-header\">\n<p class=\"entry-title\"><span style=\"color: #a5a7b7; font-family: sans-serif; font-size: inherit; font-weight: 400;\">I have worked on a range of installations and interactives for galleries, museums and public events and can act as designer, programmer and artist depending on the specific job. A brief selection of project is listed below, more information is available on request.</span></p>\n</div>\n<div class=\"entry-container\">\n<div class=\"entry-content\">\n<article>\n<h2><strong>The Wilding Of Mars</strong></h2>\n<figure id=\"attachment_1627\" class=\"wp-caption alignnone\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/20-Better-Nature-Ginsberg_photo-bettina-matthiesen.jpg\" alt=\"\" width=\"5315\" height=\"3463\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/20-Better-Nature-Ginsberg_photo-bettina-matthiesen-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/20-Better-Nature-Ginsberg_photo-bettina-matthiesen-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/20-Better-Nature-Ginsberg_photo-bettina-matthiesen-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/20-Better-Nature-Ginsberg_photo-bettina-matthiesen-xl.jpg 1024w\"></figure>\n<br>\n<figcaption class=\"wp-caption-text\">Better Nature Exhibition by Alexandra Daisy Ginsberg at Vitra Design Museum</figcaption>\n</figure>\nI was approached by the studio of <a href=\"https://www.daisyginsberg.com/studio.php\" rel=\"noopener\" target=\"_blank\">Alexandra Daisy Ginsberg</a> to design software for the Wilding of Mars Project. The project is described as follows.\n<p><em>Human dreams of colonisation are not limited to Earth. We see Mars, untouched by Earth life as barren, treacherous, beautiful; another planet to colonise. But humans invariably become exploiters. Instead, could we imagine Mars colonised only by plants, flourishing without us? The Wilding of Mars simulates the growth of a planetary wilderness, seeded with Earth life forms. In exhibition, a wild garden on Mars thrives over millennia, its growth visible over human hours. The pioneers are seeded in stages as conditions become more tolerable. The plants spread north from the South Pole, developing an ecosystem determined by global and local parameters of water, temperature, and nutrients.</em></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/marsscape1.jpg\" alt=\"\" width=\"1908\" height=\"999\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/marsscape1-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/marsscape1-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/marsscape1-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/marsscape1-xl.jpg 1024w\"></figure>\n<p>I worked with Daisy and the team to develop a software simulation that would represent the possible outcomes of a martian rewilding. The project required a complex simulation that would calculate the spread of multiple species across a variety of terrains. My code took into account local environmental factors such as water, gas and soil nutrition in order to calculate the spread of thousands of simulated plant entities across the three martian seeding locations. Each species creates a ‘map’ of growth across the terrain and is also capable of mutating in ways that effect both its performance and its aesthetic form.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/190517_The-Wilding-of-Mars_still_01.jpg\" alt=\"\" width=\"3820\" height=\"2148\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/190517_The-Wilding-of-Mars_still_01-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/190517_The-Wilding-of-Mars_still_01-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/190517_The-Wilding-of-Mars_still_01-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/190517_The-Wilding-of-Mars_still_01-xl.jpg 1024w\"></figure>\n<p>In addition to large scale aerial views each simulated location featured a close up view of successful plants growing in small scale local environs. The 3d models for these plants were generated from abstracted structural form data (stored in a similar structure to an L-System) which allowed them represent aesthetic mutations that might have occurred throughout the life of the species (potentially over millions of years). The origin (seed) species were structured as their real-world equivalents are, but over time these forms could mutate into new variant species.</p>\n<figure id=\"attachment_1628\" class=\"wp-caption alignnone\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/27-Better-Nature-Ginsberg_Photo-Bettina-Matthiesen-Matthiesen.jpg\" alt=\"\" width=\"5315\" height=\"3262\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/27-Better-Nature-Ginsberg_Photo-Bettina-Matthiesen-Matthiesen-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/27-Better-Nature-Ginsberg_Photo-Bettina-Matthiesen-Matthiesen-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/27-Better-Nature-Ginsberg_Photo-Bettina-Matthiesen-Matthiesen-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/27-Better-Nature-Ginsberg_Photo-Bettina-Matthiesen-Matthiesen-xl.jpg 1024w\"></figure>\n<figcaption class=\"wp-caption-text\">Better Nature Exhibition by Alexandra Daisy Ginsberg at Vitra Design Museum</figcaption>\n</figure>\nThe work shows different seeding locations on mars, with each terrain displaying both a large scale view of the current growth maps and smaller scale views where the individual plants could be represented.</article>\n<article></article>\n<article>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/190517_The-Wilding-of-Mars_still_02.jpg\" alt=\"\" width=\"3820\" height=\"2148\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/190517_The-Wilding-of-Mars_still_02-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/190517_The-Wilding-of-Mars_still_02-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/190517_The-Wilding-of-Mars_still_02-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/190517_The-Wilding-of-Mars_still_02-xl.jpg 1024w\"></figure>\n</article>\n<article></article>\n<article></article>\n<article></article>\n<article><span style=\"font-size: inherit;\">A record of the evolved forms is output over the course of the simulation, storing the lifespan of species, their forms and their performance.</span>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/2019-07-27-16_18_39-Descendants-Dropbox.png\" alt=\"\" width=\"654\" height=\"714\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/2019-07-27-16_18_39-Descendants-Dropbox-xs.png 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/2019-07-27-16_18_39-Descendants-Dropbox-sm.png 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/2019-07-27-16_18_39-Descendants-Dropbox-md.png 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/2019-07-27-16_18_39-Descendants-Dropbox-xl.png 1024w\"></figure>\n<h2>Flutter</h2>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/buttercap1.jpg\" alt=\"\" width=\"500\" height=\"297\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/buttercap1-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/buttercap1-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/buttercap1-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/buttercap1-xl.jpg 1024w\"></figure>\n<p>For this project I designed and wrote software that brought paper-craft made butterflies to life and then recorded each entity to a database. Visitors to the installation were invited to design their own butterfly on card in a series of craft workshops and the resulting paper models were scanned and trimmed by my application into a textures that were then used to generate 3d butterflies. These 3d versions flew around the workshop space (at the southbank centre and later at the millennium galleries) and the participants could find their own contribution fluttering amongst the growing flock.</p>\n<p> </p>\n<center>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/butter2.jpg\" alt=\"\" width=\"500\" height=\"400\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/butter2-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/butter2-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/butter2-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/butter2-xl.jpg 1024w\"></figure>\n</center>\n<p> </p>\n<p>Each butterfly was linked to an id and QR code which could be returned to the exhibition and when placed in view of a local scanner would call the related butterfly back into the installation projector scene.</p>\n<p> </p>\n<div class=\"fluid-width-video-wrapper\"><div class=\"post__iframe\"><iframe loading=\"lazy\" width=\"674\" height=\"336\" style=\"width: 674px; height: 336px;\" src=\"http://player.vimeo.com/video/5189909\" frameborder=\"0\" name=\"fitvid0\" data-mce-fragment=\"1\"></iframe></div></div>\n<p>A later iteration resulted in over 1400 butterflies being created in 13 school workshops across South Yorkshire. Laura Mundy and Janet Jennings ran the workshops, producing a vast database of butterflies that were brought to life on data projectors during the workshops and then stored for later. After all the workshops had been completed where was an exhibition at the Millenium Galleries in Sheffield where children could bring their butterflies back to life in the installation by visiting with their original paper versions.</p>\n<p> </p>\n<center>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/flutterwork.jpg\" alt=\"\" width=\"500\" height=\"375\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/flutterwork-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/flutterwork-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/flutterwork-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/flutterwork-xl.jpg 1024w\"></figure>\n</center>\n<h2>UntitledApplication</h2>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/expodance.jpg\" alt=\"\" width=\"2048\" height=\"1536\" sizes=\"(min-width: 760px) 660px, calc(93.18vw - 30px)\" srcset=\"https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/expodance-xs.jpg 320w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/expodance-sm.jpg 480w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/expodance-md.jpg 768w ,https://tomnullpointer.github.io/gh-pages/media/posts/10/responsive/expodance-xl.jpg 1024w\"></figure>\n<p>Untitled Application is an interactive sound piece commissioned by MAAP and SAM for the Leeds Expo. Its an open air work hosted on one of the BBCs ‘big screens’, a range of large outdoor LCD displays in major cities of the UK. The piece itself was produced for the LEEDs Expo, a festival of sound art.</p>\n<p>The work is a two part application. The visual part is written in C++ using openframeworks and opencv. It takes a council CCTV camera as a video feed and performs a series of motion tracking, blob detection functions on the input. Audience movement is used to trigger simple graphic elements on the screen which are superimposed on the camera image. People can generate interactive patterns through their physical movement across the city square.</p>\n<div class=\"fluid-width-video-wrapper\"><div class=\"post__iframe\"><iframe loading=\"lazy\" width=\"668\" height=\"333\" style=\"width: 668px; height: 333px;\" src=\"http://player.vimeo.com/video/6782757\" frameborder=\"0\" name=\"fitvid1\" data-mce-fragment=\"1\"></iframe></div></div>\n<p>The second phase of the system is a synthesis engine written in PD (puredata) which communicates via OSC to the C++ application. When a person triggers an animation in a particular area of the screen a message is sent to the synthesis app which plays an apporpriate tone. The notes are selected from three sets of harmonic scales and underpinned by a phased/droning 4 note sitar stye chord. The notes themselves alter pitch and timbre depending on the players behaviour and the generative variables in the synthesis system. Each of the three tonal sets rlates to a specific graphic style in the visuals.</p>\n<p>It’s been great to see people playing with the piece and working out how to draw/compose with bikes, buggies, wheelchairs, skateboards and even spacehoppers.</p>\n</article>\n</div>\n</div>",
            "image": "https://tomnullpointer.github.io/gh-pages/media/posts/10/20-Better-Nature-Ginsberg_photo-bettina-matthiesen-2.jpg",
            "author": {
                "name": "me"
            },
            "tags": [
                   "Procedural Generation",
                   "Installation Art",
                   "Archive"
            ],
            "date_published": "2025-10-04T19:01:52+01:00",
            "date_modified": "2025-10-05T10:22:28+01:00"
        }
    ]
}
